<!-- #region -->
# Fairness on Machine Learning

## Overview
As Data Scientist we usually develop analytical models to predict our clients' behaviors such as who are more likely to buy a new product or who are going to cancel their subscription. Analytics models are also designed to distinguish one group from the rest and prioritize them, such as who to approve a loan and who to reject. It is here that special care must be taken because it is possible to have models that in some way discriminate or favor a group of people based on sensitive variables such as sex, race or location. Moreover, many times data scientists seek to have models with the best metrics, high precision or accuracy, but behind it, it may be inducing discrimination just by having the highest metrics in model training. That is why it is very important to have tools that allow us to visualize if this kind of situation is occurring at the moment that we train an analytics model. Fairlearn is an open source machine learning toolkit that allow us to build fairer and more inclusive machine learning models. We know that Artificial Intelligence is a field that is going to be more and more present on our lives and thus it will have a broad impact on society, however it use has to be fair. We have to ensure that all analytics models we develop treat everyone fairly.

## Example of unfair model


## Use of Fairlearn tool to mitigate disparity

## Fairness on AzureML
We can leverage the advantages of the Fairness package on AzureML.

## Conclusions and Further steps

## Sources
https://www.microsoft.com/en-us/ai/responsible-ai
https://www.youtube.com/watch?v=Ts6tB2p97ek&ab_channel=MicrosoftDeveloper
https://github.com/fairlearn/fairlearn
https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml

<!-- #endregion -->
